_target_: src.data.t5_datamodule.T5DataModule

data_dir: data/cleaned_pretraining
# path to directory where tokenizer files will be saved / loaded
# this directory should contain sentencepiece.model, config.json etc.
# directory will be created if it doesn't exist

# use cleaned dataset path defined above

# ensure to export PROJECT_ROOT env var or set paths.root_dir to '.'

tokenizer_path: data/tokenizer

batch_size: 8
num_workers: 4
pin_memory: true

max_length: 512
corruption_rate: 0.15
mean_span_length: 3

train_val_split: [0.95, 0.05] 