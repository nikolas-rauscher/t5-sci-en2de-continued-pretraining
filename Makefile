help:  ## Show help
	@grep -E '^[.a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-30s\033[0m %s\n", $$1, $$2}'

clean: ## Clean autogenerated files
	rm -rf dist
	find . -type f -name "*.DS_Store" -ls -delete
	find . | grep -E "(__pycache__|\.pyc|\.pyo)" | xargs rm -rf
	find . | grep -E ".pytest_cache" | xargs rm -rf
	find . | grep -E ".ipynb_checkpoints" | xargs rm -rf
	rm -f .coverage

clean-logs: ## Clean logs
	rm -rf logs/**

format: ## Run pre-commit hooks
	pre-commit run -a

sync: ## Merge changes from main branch to your current branch
	git pull
	git pull origin main

test: ## Run not slow tests
	pytest -k "not slow"

test-full: ## Run all tests
	pytest

train: ## Train the model
	python src/train.py

setup:  ## Show environment activation instructions
	@echo "To activate your virtual environment, run:"
	@echo "source .venv/bin/activate"

setup-spacy-env: ## Setup separate spaCy environment for stats
	python -m venv .venv_spacy_stats
	.venv_spacy_stats/bin/pip install --upgrade pip setuptools wheel
	.venv_spacy_stats/bin/pip install -r requirements_spacy_stats.txt
	.venv_spacy_stats/bin/pip install -e external/datatrove

# Data preprocessing commands
clean-data: ## Run data cleaning pipeline  
	.venv/bin/python src/dataprep/pipelines/clean_data.py

preprocess-windows: ## Preprocess T5 SentencePiece token counts for T5 training (windows computed on-the-fly)
	.venv/bin/python src/dataprep/pipelines/run_sliding_windows.py

preprocess-windows-test: ## Preprocess T5 SentencePiece token counts (test mode - limit_documents=100)
	.venv/bin/python src/dataprep/pipelines/run_sliding_windows.py sliding_windows.limit_documents=100

stats_p1: ## Run standard stats (NumPy 2.0 compatible)
	.venv/bin/python src/dataprep/pipelines/run_stats.py

stats_p2: ## Run spaCy-based stats (SentenceStats, WordStats, LangStats)
	.venv_spacy_stats/bin/python src/dataprep/pipelines/run_spacy_stats.py

stats-all: ## Run all stats pipelines (chained: standard -> spacy) 
	@echo "Running stats pipeline (chained)..."
	@echo "Step 1: Standard stats with enriched docs..."
	.venv/bin/python src/dataprep/pipelines/run_stats.py stats.save_enriched_docs=true
	@echo "Step 2: spaCy stats on enriched docs..."
	.venv_spacy_stats/bin/python src/dataprep/pipelines/run_spacy_stats.py
	@echo "Complete stats pipeline finished!"

stats-test: ## Run stats with limited documents for testing (chained)
	@echo "Running test stats pipeline (chained)..."
	.venv/bin/python src/dataprep/pipelines/run_stats.py stats.save_enriched_docs=true stats.limit_documents=10 stats.tasks=16 stats.workers=16
	.venv_spacy_stats/bin/python src/dataprep/pipelines/run_spacy_stats.py stats.limit_documents=10 stats.tasks=16 stats.workers=16
	@echo "Test pipeline completed!"

stats-test-safe: ## Run test with separate output to avoid conflicts
	@echo "Running SAFE test stats pipeline (separate output)..."
	.venv/bin/python src/dataprep/pipelines/run_stats.py stats.save_enriched_docs=true stats.paths.output_folder=data/statistics_test/ stats.limit_documents=200 stats.tasks=16 stats.workers=16
	.venv_spacy_stats/bin/python src/dataprep/pipelines/run_spacy_stats.py stats.paths.input_folder=data/statistics_test/enriched_documents_statistics_v1/ stats.paths.output_folder=data/statistics_test/ stats.limit_documents=200 stats.tasks=16 stats.workers=16
	@echo "Safe test pipeline completed! Output in: data/statistics_test/"


stats-production-chained: ## Run production chained pipeline with high-performance settings
	@echo "Running PRODUCTION chained stats pipeline..."
	@echo "Step 1: Standard stats with enriched docs (64 CPUs)..."
	.venv/bin/python src/dataprep/pipelines/run_stats.py stats.save_enriched_docs=true stats.paths.output_folder=data/statistics_production/ stats.tasks=200 stats.workers=62
	@echo "Step 2: spaCy stats on enriched docs (64 CPUs)..."
	.venv_spacy_stats/bin/python src/dataprep/pipelines/run_spacy_stats.py stats.paths.input_folder=data/statistics_production/enriched_documents_statistics_v1/ stats.paths.output_folder=data/statistics_production/ stats.tasks=200 stats.workers=62
	@echo "Production pipeline completed! Output in: data/statistics_production/"

# Stats analysis commands
analyze: ## Basic stats analysis with plots and CSV export
	.venv_spacy_stats/bin/python scripts/analyze_stats.py

# Web diff viewer commands
# Note: ngrok warning page is automatically bypassed with ngrok-skip-browser-warning header
web-diff: ## Start web diff viewer with default settings
	.venv/bin/python scripts/util/web_diff_viewer_simple.py --gold-dir data/statistics_data_gold/enriched_documents_statistics_v2 --cleaned-dir data/cleaned-production --ngrok --list-categories-dir wandb/run-20250612_141655-cpwqgv8t/files/media/table/tables

web-diff-ngrok: ## Start web diff viewer with ngrok tunnel for external access
	.venv/bin/python scripts/util/web_diff_viewer_simple.py --gold-dir data/statistics_data_gold/enriched_documents_statistics_v2 --cleaned-dir data/cleaned-production --ngrok

web-diff-custom: ## Start web diff viewer with custom directories
	@echo "Usage: make web-diff-custom GOLD_DIR=path/to/gold CLEANED_DIR=path/to/cleaned LIST_CATEGORIES_DIR=path/to/categories"
	.venv/bin/python scripts/util/web_diff_viewer_simple.py --gold-dir $(GOLD_DIR) --cleaned-dir $(CLEANED_DIR) --list-categories-dir $(LIST_CATEGORIES_DIR)

web-diff-test: ## Start web diff viewer with test data directories
	.venv/bin/python scripts/util/web_diff_viewer_simple.py --gold-dir data/statistics_data_gold/enriched_documents_statistics_v2 --cleaned-dir data/cleaned --ngrok --list-categories-dir wandb/run-20250612_141655-cpwqgv8t/files/media/table/tables
